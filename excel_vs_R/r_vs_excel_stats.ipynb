{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "r_vs_excel_stats.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bca2/593/blob/master/r_vs_excel_stats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20Njaiuaa0m-",
        "colab_type": "text"
      },
      "source": [
        "# Purpose\n",
        "\n",
        "This document is intended to inform instructors on when and why a statistics package like R should be used over Excel.\n",
        "\n",
        "Code has been hidden.\n",
        "\n",
        "There is a .csv file required (\"**test2.csv**\"), and it should be on github.\n",
        "\n",
        "\n",
        "# Statistics: R vs Excel\n",
        "\n",
        "Excel (or some sort of spreadsheet) skills are defininitely something that all students attending a post-secondary institution will need.\n",
        "\n",
        "Originally, I learned excel for stats, and I still use excel for storing data (many people/organizations do).\n",
        "\n",
        "However, Excel is not a serious (or even competent) statistics program, and should be avoided if the analysis is anything more complicated than simple linear regression or a t-test (balanced ANOVAs are probably fine too).\n",
        "Excel was not built to do statistics properly.\n",
        "Be warned that the statistics Excel claims to do outstrip what it can actually do correctly.\n",
        "\n",
        "# Non-linear data\n",
        "\n",
        "Excel does just fine with linear regression but incorrectly fits non-linear data (except maybe polynomial fits, those should just be extensions of a linear fit).\n",
        "\n",
        "Many non-linear problems in science are non-linear: exponential growth or decay, logistic growth, Michaelisâ€“Menten kinetics, sinusoidal etc.\n",
        "\n",
        "Here's the thing: Excel doesn't actually fit non-linear models even though it claims to fit exponential, logarithmic, and power models (see the trendline options for graphs) .\n",
        "Instead, it linearizes the data (transforms the data) so that it's linear, then backtransforms the data.\n",
        "\n",
        "This is an example of case where it doesn't work.\n",
        "\n",
        "## Exponential decay\n",
        "\n",
        "The data we'll be fitting a line to show exponential decay.\n",
        "A general form of the equation is:\n",
        "\n",
        "$$y = A\\cdot e^{x \\cdot  r_{max}}$$\n",
        "\n",
        "Excel will log-transform the data, fit a linear model, and then backtransform the data.\n",
        "The model excel will actually fit is:\n",
        "\n",
        "\\begin{align}\n",
        "\\begin{aligned}\n",
        "\\ln(y) &= \\ln(A \\cdot e^{x \\cdot  r_{max}})\\\\\n",
        "           &= \\ln(A) + x \\cdot  r_{max}\n",
        "\\end{aligned}\n",
        "\\end{align}\n",
        "\n",
        "This transformation is completely legitimate.\n",
        "\n",
        "### Why linearization usually doesn't work\n",
        "\n",
        "Unfortunately, these equations are incomplete.\n",
        "The true equation that represents our data is:\n",
        "\n",
        "$$y_i = A\\cdot e^{x_i \\cdot  r_{max}} + \\epsilon_i$$\n",
        "\n",
        "where $y_i$ is the $i^{th}$ data value and $\\epsilon_i$ is the error associated with the $i^{th}$ data value.\n",
        "Errors are assumed to be (and are generally pretty close) normally distributed random values with a mean of 0 and constant variance (to be estimated from the residuals).\n",
        "\n",
        "$$\\epsilon \\sim  N(0, \\sigma^2)$$\n",
        "\n",
        "Many statistical procedures assume that the errors follow this unknown distribution.\n",
        "Simple linear regression, for example, does.\n",
        "Non-linear regression does, too.\n",
        "\n",
        "When Excel performs the transformation to linearize the data, the error is transformed.\n",
        "\n",
        "$$ln(y) = \\ln(A\\cdot e^{x \\cdot  r_{max}}+\\epsilon)$$\n",
        "\n",
        "The transformation is no longer nice and clean.\n",
        "\n",
        "If the errors were approximately $\\epsilon \\sim  N(0, \\sigma^2)$ before the transformation, then they likely will not be after the transformation.\n",
        "This means that the simple linear regression that Excel performs on the transformed data is innapropriate since we fail to meet one of the model assumptions (either the residuals are not normal, the variance isn't constant, or both).\n",
        "\n",
        "Below is an analysis of simulated data output showing the differences between Excel and R.\n",
        "The simulated data is exponential with $A=100$ and $ r_{max}=-0.025$ with $\\epsilon \\sim N(0, 10^2)$.\n",
        "\n",
        "\n",
        "### When linearization would work\n",
        "\n",
        "If the errors become normally distributed and homogenous due to the transformation then linearization could work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52SDj_vhayKg",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Activate R\n",
        "# The following code lets us speak in the R language while working from within Python\n",
        "\n",
        "%load_ext rpy2.ipython\n",
        "\n",
        "# Using R inside python in this way tends to produce warnings\n",
        "# The warnings don't seem to have an effect on the desired output, so I'm just going to suppress the warnings.\n",
        "# You can go ahead and run the code with and without warnings by excluding/including the following code:\n",
        "\n",
        "import warnings\n",
        "from rpy2.rinterface import RRuntimeWarning\n",
        "warnings.filterwarnings(\"ignore\", category=RRuntimeWarning)\n",
        "\n",
        "# To comment out code, just use the pound sign (hashtag) \"#\"\n",
        "# Code that's been commented out will not be run, just like this comment I'm writing right now.\n",
        "# Comments help us in two major ways:\n",
        "#   1. You can easily leave instructions or clarifications in your code for other people or for future you.\n",
        "#   2. You can see how your code runs without certain lines of code without actually deleting your code.\n",
        "#       My advice: Try not to delete your code. You may change your mind later, and it's good to have it readily available."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfUJFbwow5e5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaJqQxmsaxDA",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Import data (test2.csv)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ng9cHdzuUKz",
        "colab_type": "text"
      },
      "source": [
        "The \"test2.csv\" data should be available in the github folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUJH-wd5fH8y",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Non-linear model fit\n",
        "%%R\n",
        "\n",
        "library(nlme)\n",
        "library(tidyr)\n",
        "library(dplyr)\n",
        "\n",
        "exp = read.csv(\"test2.csv\")\n",
        "\n",
        "exp = exp%>%\n",
        "    mutate(y_act = 100*exp(-x*.025))\n",
        "\n",
        "A_start=100\n",
        "\n",
        "k_start=-.03\n",
        "\n",
        "fit_exp <- nls(data=exp,\n",
        "            formula = y ~ A*exp(x*k),\n",
        "            start = list(A=A_start,k=k_start))\n",
        "summary(fit_exp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MDvIh64xtEi",
        "colab_type": "text"
      },
      "source": [
        "Note that our estimates are:\n",
        "\n",
        "\\begin{align}\n",
        "\\begin{aligned}\n",
        " A&=97.7\\\\\n",
        "  r_{max}&=-0.0248\\\\\n",
        " \\sigma &= 9.697\n",
        "\\end{aligned}\n",
        "\\end{align}\n",
        "\n",
        "...which is pretty good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duWnPSP3oTzf",
        "colab_type": "text"
      },
      "source": [
        "### Checking the residuals\n",
        "\n",
        "We generally graph a scatterplot of the residuals to make sure that they're approximately normal and have equal variance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOLjQkQCf6fk",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Residuals from the R fit (residuals seem homogeneous, good)\n",
        "%%R\n",
        "plot(fit_exp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AvylwDlolZM",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Residuals from the R fit (residuals seem normalish, good)\n",
        "%%R\n",
        "qqnorm(residuals(fit_exp))\n",
        "qqline(residuals(fit_exp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHjbE0kFssJw",
        "colab_type": "text"
      },
      "source": [
        "#### R residual analysis\n",
        "\n",
        "The residuals seem homogeneous.\n",
        "The graph looks more or less like a shot-gun blast, it's random and there's no real pattern.\n",
        "\n",
        "The residuals are normalish (Q-Q plot).\n",
        "Perfectly normal residuals would all fall on the line, our data is pretty close."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgScH-pQf7h6",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Model fits (R = green, Excel = Red, True equation = blue)\n",
        "%%R\n",
        "plot(exp$x,exp$y)\n",
        "lines(predict(fit_exp), col=\"green\")\n",
        "lines(exp$x,exp$excel_y, col=\"red\")\n",
        "lines(exp$x,exp$y_act, col=\"blue\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKBApwd5FHH4",
        "colab_type": "text"
      },
      "source": [
        "The non-linear model fit with R is clearly closer to the true equation.\n",
        "In this case we know what the true equation is because the data were simulated by me using R."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL2JTj7TtHkQ",
        "colab_type": "text"
      },
      "source": [
        "## Residual analysis of the excel fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DkhhdahpzmB",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Residuals from the Excel fit (obvious pattern, not good)\n",
        "%%R\n",
        "\n",
        "library(dplyr)\n",
        "library(tidyr)\n",
        "\n",
        "exp2 = exp%>%\n",
        "    mutate(excel_res = (excel_y-y)/11.72071)\n",
        "  \n",
        "plot(x=exp2$excel_y, y=exp2$excel_res)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8voSh37Vq4Zv",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Residuals from the Excel fit (residuals seem normalish, maybe not as good as before, but not awful)\n",
        "%%R\n",
        "qqnorm(exp2$excel_res)\n",
        "qqline(exp2$excel_res)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp_yxlI30XSw",
        "colab_type": "text"
      },
      "source": [
        "# The Tradeoff\n",
        "\n",
        "R does the correct analysis, however, a non-linear analyis doesn't necessarily just work out of the box.\n",
        "\n",
        "Non-linear models require starting values, which can be a pain.\n",
        "Linear models are so straight forward that you could do them by hand with pen and paper (if you have some linear algebra in your background).\n",
        "\n",
        "Fitting non-linear models is sort of a guessing game.\n",
        "The algorithm fitting the model will take the starting values that you provide and attempt to improve upon them by making tiny changes.\n",
        "Improvement here means reducing the resisdual sums of squares to the point where it identifies the parameter values that result in the minimum sums of squares (identical to the goal of a simple linear model).\n",
        "\n",
        "This can be a little finicky because there may be multiple local minima even though there's only one absolute minimum.\n",
        "If the starting parameters are incorrectly specified then the algorithm can get stuck on a local minimum resulting in poor estimates.\n",
        "Additionally there can be other issues, especially with complex models.\n",
        "This isn't a reason not to do a non-linear models, but it's a reason to keep the non-linear models simple for high school.\n",
        "\n",
        "## Guessing good starting values: could be a good exercise for students\n",
        "\n",
        "We need to guess good starting values for the non-linear model to work properly.\n",
        "\n",
        "Let's start with $A$.\n",
        "\n",
        "$$y = A\\cdot e^{x \\cdot k}$$\n",
        "\n",
        "If $x=0$ then $y=A$ (because $e^0=1$).\n",
        "\n",
        "We can probably get a good guess of $A$ from a scatterplot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r06lOuH2Fik",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Guessing A from a graph\n",
        "%%R\n",
        "library(ggplot2)\n",
        "\n",
        "plot = ggplot(exp, aes(x = x, y = y))\n",
        "plot = plot + geom_point()\n",
        "plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF5mBYVe3lnB",
        "colab_type": "text"
      },
      "source": [
        "A good starting value of $A$ would be around 100.\n",
        "\n",
        "#### $r_{max}$ is a bit tougher, we can't just easily guess it from the graph\n",
        "\n",
        "We can cheat a little bit and use linearization to get an estimate of $k$.\n",
        "This is good for getting in the right ballpark, but it's not our final estimate.\n",
        "\n",
        "Use this transformation on all observations and then take the average.\n",
        "\n",
        "$$\\frac{ln(y_i)-\\ln(A)}{x_i}= r_{max}$$\n",
        "           \n",
        "...which is about $-0.03$.\n",
        "\n",
        "\n",
        "###  Linearized model to get starting values\n",
        "\n",
        "We can also just fit the linear model (this is what excel does) and use those estimates in our non-linear model.\n",
        "This won't work for every non-linear model, but it will with this exponential model.\n",
        "\n",
        "The log-transformed model (approximately) looks like this:\n",
        "\n",
        "$$\\ln{y}=\\ln{A} + r_{max} \\cdot x$$\n",
        "\n",
        "\n",
        "\n",
        "Notice that if we fit this linear model, our intercept $\\beta_0 = \\ln{A}$ and our slope $\\beta_1 = r_{max}$.\n",
        "For this model these are probably pretty good starting values.\n",
        "\n",
        "$r_{max}$ seems pretty easy to find.To find $A$:\n",
        "\n",
        "\\begin{align}\n",
        "\\begin{aligned}\n",
        "\\beta_0 &= \\ln{A}\\\\\n",
        "    e^{\\beta_0}&= A\n",
        "\\end{aligned}\n",
        "\\end{align}"
      ]
    }
  ]
}
